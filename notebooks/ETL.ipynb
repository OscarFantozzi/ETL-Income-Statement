{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d300623-a7ec-4dec-9755-3336f5c216c1",
   "metadata": {},
   "source": [
    "## 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba49070-2688-47c2-a7a3-ee1badef3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc \n",
    "import os\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52762db7-4fc6-42fe-b569-3b41aba1e5c4",
   "metadata": {},
   "source": [
    "### 0.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8bb25dc-52e0-43b5-bdd9-f96a6948215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(server, database_name , path):\n",
    "    # create pyodbc connection\n",
    "    conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                          f'Server={server};'\n",
    "                          'Trusted_Connection=yes;')\n",
    "\n",
    "        \n",
    "    # check connection\n",
    "    if conn:\n",
    "        print( \"Successfull Connection\" )\n",
    "    else:\n",
    "        print( \"Connection Failded\" )\n",
    "\n",
    "    # create a cursor\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # check if a database already exists\n",
    "    database_name = database_name\n",
    "    check_db = f'''\n",
    "        IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{database_name}' )\n",
    "            BEGIN\n",
    "            CREATE DATABASE {database_name}\n",
    "            END\n",
    "    '''\n",
    "    # execute check_db query\n",
    "    cursor.execute( check_db )\n",
    "\n",
    "    # create sql alchemy connection\n",
    "    connection_string = f'mssql+pyodbc://{server}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "    # create engine\n",
    "    engine = create_engine( connection_string )\n",
    "\n",
    "    # for each file in folder load csv files into database\n",
    "    path = os.listdir(path)\n",
    "    for file in path:\n",
    "            \n",
    "        file_name = os.path.join(path, file)\n",
    "\n",
    "        table_name = os.path.basename( file_name )\n",
    "\n",
    "        if file.endswith( '.csv' ):\n",
    "            \n",
    "            df = pd.read_csv( table_name, encoding = 'UTF-8' )\n",
    "            \n",
    "            df.to_sql( name = table_name , con = engine , if_exists= 'replace', index = False)\n",
    "            \n",
    "            print( f'{ table_name } has been loaded into database' )\n",
    "\n",
    "        else:\n",
    "            \"File not found\"\n",
    "\n",
    "    # closing cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def transform( server_name , database_name ):\n",
    "\n",
    "    SERVER = server_name\n",
    "    # create sql alchemy connection\n",
    "    connection_string = f'mssql+pyodbc://{SERVER}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    \n",
    "    # create engine\n",
    "    engine = create_engine( connection_string )\n",
    "\n",
    "    # inspect database schema\n",
    "    inspector = inspect( engine )\n",
    "\n",
    "    # get the list of tables in the database\n",
    "    tables = inspector.get_table_names()\n",
    "\n",
    "    # create empty dict\n",
    "    tables_dict = {}\n",
    "    df_Lan_final = pd.DataFrame()\n",
    "    \n",
    "    for file in tables:\n",
    "        \n",
    "\n",
    "        if file == 'dEstruturaDRE.csv':\n",
    "            # read data\n",
    "            query = 'SELECT * FROM [dbo].[dEstruturaDRE.csv]'\n",
    "            df_dEstruturaDre = pd.read_sql( query , engine )\n",
    "\n",
    "            # drop na\n",
    "            df_dEstruturaDre = df_dEstruturaDre.dropna(axis = 0)\n",
    "\n",
    "            # change dtypes\n",
    "            df_dEstruturaDre['id']                = df_dEstruturaDre['id'].astype( 'str' )\n",
    "            df_dEstruturaDre['index']             = df_dEstruturaDre['index'].astype( 'int64' )\n",
    "            df_dEstruturaDre['contaGerencial']    = df_dEstruturaDre['contaGerencial'].astype( 'str' )\n",
    "            df_dEstruturaDre['subtotal']          = df_dEstruturaDre['subtotal'].astype( 'int64' )\n",
    "            df_dEstruturaDre['empresa']           = df_dEstruturaDre['empresa'].astype( 'str' )\n",
    "\n",
    "\n",
    "            # rename columns \n",
    "            df_dEstruturaDre = df_dEstruturaDre.rename(columns = \n",
    "                                    {'contaGerencial' : 'ManagementAccount', \n",
    "                                      'empresa' : 'Branch', \n",
    "                                      'subtotal' : 'Subtotal', \n",
    "                                      'index' : 'Index'}  )\n",
    "\n",
    "            tables_dict[file] = df_dEstruturaDre\n",
    "            print( f'{file} has been cleaned. It has {df_dEstruturaDre.shape[0]} rows ' )\n",
    "\n",
    "\n",
    "        elif file == 'dPlanoConta.csv':\n",
    "            \n",
    "            # read data\n",
    "            query = 'SELECT * FROM [dbo].[dPlanoConta.csv]'\n",
    "            df_dPlanoConta = pd.read_sql( query , engine )\n",
    "\n",
    "            # drop na\n",
    "            df_dPlanoConta = df_dPlanoConta.dropna(axis = 0)\n",
    "\n",
    "            # change dtypes\n",
    "            df_dPlanoConta['mascaraDRE_id'] = df_dPlanoConta['mascaraDRE_id'].astype( 'str' )\n",
    "\n",
    "            # rename columns\n",
    "            columns = {\"descricaoN1\"   : \"DescriptionLevel1\", \n",
    "             \"descricaoN2\"   : \"DescriptionLevel2\", \n",
    "             \"detalharN2\"    : \"DetailLevel2?\",\n",
    "             \"mascaraDRE_id\" : \"IncomeStatementTemplate_id\",\n",
    "            \"tipoLancamento\" : \"EntryType\",\n",
    "            \"index\"          : \"Index\"}\n",
    "\n",
    "            df_dPlanoConta = df_dPlanoConta.rename( columns = columns )   \n",
    "\n",
    "            tables_dict[file] = df_dPlanoConta\n",
    "            print( f'{file} has been cleaned. It has {df_dPlanoConta.shape[0]} rows ' )\n",
    "\n",
    "\n",
    "        elif file == 'fOrcamento.csv':\n",
    "            \n",
    "            # read data\n",
    "            query = 'SELECT * FROM [dbo].[fOrcamento.csv]'\n",
    "            df_fOrcamento = pd.read_sql( query , engine )\n",
    "            \n",
    "            # drop na\n",
    "            df_fOrcamento = df_fOrcamento.dropna(axis = 0)\n",
    "\n",
    "            # change dtypes\n",
    "            df_fOrcamento['competencia_data'] = pd.to_datetime( df_fOrcamento['competencia_data'] ) \n",
    "            \n",
    "            # formatting integers numbers as .00\n",
    "            df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "            \n",
    "            # replace the last . for #\n",
    "            df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "            \n",
    "            # replace the last . for nothing\n",
    "            df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('.', '') )\n",
    "            \n",
    "            # replace # for .\n",
    "            df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "            \n",
    "            # convert value\n",
    "            df_fOrcamento['valor'] = df_fOrcamento['valor'].astype( 'float64' )\n",
    "\n",
    "            # rename columns\n",
    "            columns = {\"competencia_data\" : \"AccrualDate\",\n",
    "             \"planoContas_id\"   : \"ChartOfAccounts_id\",\n",
    "             \"valor\"            : \"Amount\"}\n",
    "            df_fOrcamento = df_fOrcamento.rename( columns =  columns )\n",
    "\n",
    "            tables_dict[file] = df_fOrcamento\n",
    "            print( f'{file} has been cleaned. It has {df_fOrcamento.shape[0]} rows ' )\n",
    "\n",
    "        elif file == 'fPrevisao.csv':\n",
    "    \n",
    "            # read data\n",
    "            query = 'SELECT * FROM [dbo].[fPrevisao.csv]'\n",
    "            df_fPrevisao = pd.read_sql( query , engine )\n",
    "\n",
    "            # drop na\n",
    "            df_fPrevisao = df_fPrevisao.dropna(axis = 0)\n",
    "\n",
    "            # change dtypes\n",
    "            df_fPrevisao['competencia_data'] = pd.to_datetime( df_fPrevisao['competencia_data'] ) \n",
    "            \n",
    "            # formatting integers numbers as .00\n",
    "            df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "            \n",
    "            # replace the last . for #\n",
    "            df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "            \n",
    "            # replace the last . for nothing\n",
    "            df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('.', '') )\n",
    "            \n",
    "            # replace # for .\n",
    "            df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "            \n",
    "            # convert value\n",
    "            df_fPrevisao['valor'] = df_fPrevisao['valor'].astype( 'float64' )\n",
    "            \n",
    "            # rename columns\n",
    "            columns = {\n",
    "                \"competencia_data\": \"AccrualDate\",\n",
    "                 \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "                 \"valor\"           : \"Amount\"}\n",
    "            \n",
    "            df_fPrevisao = df_fPrevisao.rename( columns = columns )\n",
    "\n",
    "            tables_dict[file] = df_fPrevisao\n",
    "            print( f'{file} has been cleaned. It has {df_fPrevisao.shape[0]} rows ' )\n",
    "\n",
    "        elif file.startswith( 'fLan' ):\n",
    "            \n",
    "            # read data\n",
    "            query = f'SELECT * FROM [dbo].[{file}]'\n",
    "            df_fLancamento = pd.read_sql( query , engine )\n",
    "            \n",
    "            # drop na\n",
    "            df_fLancamento = df_fLancamento.dropna(axis = 0)\n",
    "\n",
    "            # change dtypes\n",
    "            df_fLancamento['competencia_data'] = pd.to_datetime( df_fLancamento['competencia_data'] )\n",
    "\n",
    "            # formatting integers numbers as .00\n",
    "            df_fLancamento['valor'] = df_fLancamento['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "            \n",
    "            # replace the last . for #\n",
    "            df_fLancamento['valor'] = df_fLancamento['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "            \n",
    "            # replace the last . for nothing\n",
    "            df_fLancamento['valor'] = df_fLancamento['valor'].apply( lambda x: x.replace('.', '') )\n",
    "            \n",
    "            # replace # for .\n",
    "            df_fLancamento['valor'] = df_fLancamento['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "            \n",
    "            # convert value\n",
    "            df_fLancamento['valor'] = df_fLancamento['valor'].astype( 'float64' )\n",
    "            \n",
    "            # rename columns\n",
    "            columns = {\n",
    "                \"competencia_data\":\"AccrualDate\",\n",
    "                \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "                \"valor\"           : \"Amount\"\n",
    "            }\n",
    "\n",
    "            df_fLancamento = df_fLancamento.rename( columns = columns )\n",
    "\n",
    "            \n",
    "            \n",
    "            df_Lan_final = pd.concat( [df_Lan_final , df_fLancamento] , ignore_index=True )\n",
    "\n",
    "            print( f'Processing : {file}' )\n",
    "    print( f'df_Lan_final has been cleaned. It has {df_Lan_final.shape[0]} rows.' )\n",
    "\n",
    "    tables_dict['dfLancamentos'] = df_Lan_final\n",
    "\n",
    "\n",
    "        \n",
    "    return tables_dict\n",
    "\n",
    "def load( server, origin_database , destination_database ):\n",
    "\n",
    "    # db connections\n",
    "    conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      f'Server={server};'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Connecting Database:' )\n",
    "\n",
    "    if conn:\n",
    "        print( \"Successfull Connection\" )\n",
    "    else:\n",
    "        print( \"Connection Failded\" )\n",
    "    \n",
    "    # create a cursor\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print( 'Data Cleaning:' )\n",
    "\n",
    "    # cleaning data\n",
    "    tables = transform( server , origin_database )\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Creating Destination Database:' )\n",
    " \n",
    "    # check if a database already exists\n",
    "    destination_database = 'DRE_Cleaned_Data' # database where cleaned data will be stored.\n",
    "    check_db = f'''\n",
    "        IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{destination_database}' )\n",
    "            BEGIN\n",
    "            CREATE DATABASE {destination_database}\n",
    "            END\n",
    "    '''\n",
    "    # execute query\n",
    "    cursor.execute( check_db )\n",
    "    cursor.close()\n",
    "\n",
    "    print( f'{destination_database} database has been created.' )\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Data Loading:' )\n",
    "\n",
    "    # loading data\n",
    "    for table_name, df in tables.items():\n",
    "\n",
    "        df.to_sql( table_name , engine_db , if_exists= 'replace', index = False)\n",
    "        print( f'{table_name} loaded into {database_name}.' )\n",
    "    print(\"=\"*100)\n",
    "        \n",
    "    return None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61627dca-6219-4381-ab3a-552bab94cfba",
   "metadata": {},
   "source": [
    "## 0.2 Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf0aeb6c-0f74-4af4-a467-1835749344ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================================#\n",
    "# IMPORTS\n",
    "# ========================================================================================================#\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc \n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "# ========================================================================================================#\n",
    "# ETL CLASS\n",
    "# ========================================================================================================#\n",
    "class ETL:\n",
    "\n",
    "    def __init__( self, server , file_dir , staging_database_name , destination_database_name ):\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'STEP 1 :EXTRACT' )\n",
    "        \n",
    "        # create sql alchemy connection\n",
    "        self.connection_string_sql_alchemy                = f'mssql+pyodbc://{server}/{ staging_database_name }?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        self.connection_string_sql_alchemy_db_destination = f'mssql+pyodbc://{server}/{ destination_database_name }?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "        # connection string SQL Server\n",
    "        self.connection_string_sql_server = 'Driver={SQL Server};'f'Server={server};' 'Trusted_Connection=yes;'\n",
    "        \n",
    "        self.server                     = server\n",
    "        self.file_dir                   = file_dir\n",
    "        self.staging_database_name      = staging_database_name\n",
    "        self.engine                     = create_engine( self.connection_string_sql_alchemy )\n",
    "        self.engine_db_destination      = create_engine( self.connection_string_sql_alchemy_db_destination )\n",
    "        self.conn                       = pyodbc.connect(  self.connection_string_sql_server )\n",
    "        self.destination_database_name  = destination_database_name\n",
    "        self.cursor                     = self.conn.cursor()\n",
    "        print(\"=\"*100)\n",
    "        print( 'Connecting Database:' )\n",
    "\n",
    "        # check connection\n",
    "        if self.conn:\n",
    "            print( \"Successfull Connection\" )\n",
    "        else:\n",
    "            print( \"Connection Failded\" )\n",
    "            \n",
    "        self.cursor.close()\n",
    "        self.conn.close()\n",
    "\n",
    "    \n",
    "    def extract( self ):\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'Checking Existing Database:' )\n",
    "\n",
    "        # temporary connection\n",
    "        conn_temp = pyodbc.connect( self.connection_string_sql_server )\n",
    "        cursor_temp = conn_temp.cursor()\n",
    "\n",
    "        # check if a database already exists\n",
    "        check_db = f'''\n",
    "            IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{self.staging_database_name}' )\n",
    "                \n",
    "                CREATE DATABASE {self.staging_database_name}\n",
    "                \n",
    "        '''\n",
    "        # execute check_db query\n",
    "        cursor_temp.execute(check_db)\n",
    "        cursor_temp.close()\n",
    "        conn_temp.close()\n",
    "\n",
    "        print( 'Database checked' )\n",
    "\n",
    "        # for each file in folder load csv files into database\n",
    "       \n",
    "        print(\"=\"*100)\n",
    "        print( 'Loading Data:' )\n",
    "        \n",
    "        for file in os.listdir( self.file_dir ):\n",
    "\n",
    "            file = os.path.join( self.file_dir , file ) \n",
    "            \n",
    "            table_name = os.path.basename( file )\n",
    "                \n",
    "            if file.endswith( '.csv' ):\n",
    "                \n",
    "                df = pd.read_csv( file, encoding = 'UTF-8' )\n",
    "                \n",
    "                df.to_sql( name = table_name , con = self.engine , if_exists= 'replace', index = False)\n",
    "                \n",
    "                print( f'{ table_name } has been loaded into database' )\n",
    "        \n",
    "        # close engine connection\n",
    "        self.engine.dispose()\n",
    "        \n",
    "\n",
    "        return None\n",
    "        \n",
    "\n",
    "    def transform( self ):\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'STEP 2 :CLEANING DATA' )\n",
    "    \n",
    "        # inspect database schema\n",
    "        inspector = inspect( self.engine )\n",
    "\n",
    "        # get the list of tables in the database\n",
    "        tables = inspector.get_table_names()\n",
    "\n",
    "        # create empty dict\n",
    "        tables_dict = {}\n",
    "        df_Lan_final = pd.DataFrame()\n",
    "        \n",
    "        for file in tables:\n",
    "            \n",
    "            if file == 'dEstruturaDRE.csv':\n",
    "                # read data\n",
    "                query = 'SELECT * FROM [dbo].[dEstruturaDRE.csv]'\n",
    "                df_dEstruturaDre = pd.read_sql( query , self.engine )\n",
    "    \n",
    "                # drop na\n",
    "                df_dEstruturaDre = df_dEstruturaDre.dropna( axis = 0 )\n",
    "    \n",
    "                # change dtypes\n",
    "                df_dEstruturaDre['id']                = df_dEstruturaDre['id'].astype( 'str' )\n",
    "                df_dEstruturaDre['index']             = df_dEstruturaDre['index'].astype( 'int64' )\n",
    "                df_dEstruturaDre['contaGerencial']    = df_dEstruturaDre['contaGerencial'].astype( 'str' )\n",
    "                df_dEstruturaDre['subtotal']          = df_dEstruturaDre['subtotal'].astype( 'int64' )\n",
    "                df_dEstruturaDre['empresa']           = df_dEstruturaDre['empresa'].astype( 'str' )\n",
    "    \n",
    "                # rename columns \n",
    "                df_dEstruturaDre = df_dEstruturaDre.rename(columns = \n",
    "                                        {'contaGerencial' : 'ManagementAccount', \n",
    "                                          'empresa' : 'Branch', \n",
    "                                          'subtotal' : 'Subtotal', \n",
    "                                          'index' : 'Index'}  )\n",
    "    \n",
    "                tables_dict[file] = df_dEstruturaDre\n",
    "                print( f'{file} has been cleaned. It has {df_dEstruturaDre.shape[0]} rows ' )\n",
    "\n",
    "            elif file == 'dPlanoConta.csv':\n",
    "                \n",
    "                # read data\n",
    "                query = 'SELECT * FROM [dbo].[dPlanoConta.csv]'\n",
    "                df_dPlanoConta = pd.read_sql( query , self.engine )\n",
    "    \n",
    "                # drop na\n",
    "                df_dPlanoConta = df_dPlanoConta.dropna(axis = 0)\n",
    "    \n",
    "                # change dtypes\n",
    "                df_dPlanoConta['mascaraDRE_id'] = df_dPlanoConta['mascaraDRE_id'].astype( 'str' )\n",
    "    \n",
    "                # rename columns\n",
    "                columns = {\"descricaoN1\"   : \"DescriptionLevel1\", \n",
    "                 \"descricaoN2\"   : \"DescriptionLevel2\", \n",
    "                 \"detalharN2\"    : \"DetailLevel2?\",\n",
    "                 \"mascaraDRE_id\" : \"IncomeStatementTemplate_id\",\n",
    "                \"tipoLancamento\" : \"EntryType\",\n",
    "                \"index\"          : \"Index\"}\n",
    "    \n",
    "                df_dPlanoConta = df_dPlanoConta.rename( columns = columns )   \n",
    "    \n",
    "                tables_dict[file] = df_dPlanoConta\n",
    "                print( f'{file} has been cleaned. It has {df_dPlanoConta.shape[0]} rows ' )\n",
    "\n",
    "            elif file == 'fOrcamento.csv':\n",
    "                \n",
    "                # read data\n",
    "                query = 'SELECT * FROM [dbo].[fOrcamento.csv]'\n",
    "                df_fOrcamento = pd.read_sql( query , self.engine )\n",
    "                \n",
    "                # drop na\n",
    "                df_fOrcamento = df_fOrcamento.dropna(axis = 0)\n",
    "    \n",
    "                # change dtypes\n",
    "                df_fOrcamento['competencia_data'] = pd.to_datetime( df_fOrcamento['competencia_data'] ) \n",
    "                \n",
    "                # formatting integers numbers as .00\n",
    "                df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "                \n",
    "                # replace the last . for #\n",
    "                df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "                \n",
    "                # replace the last . for nothing\n",
    "                df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('.', '') )\n",
    "                \n",
    "                # replace # for .\n",
    "                df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "                \n",
    "                # convert value\n",
    "                df_fOrcamento['valor'] = df_fOrcamento['valor'].astype( 'float64' )\n",
    "    \n",
    "                # rename columns\n",
    "                columns = {\"competencia_data\" : \"AccrualDate\",\n",
    "                 \"planoContas_id\"   : \"ChartOfAccounts_id\",\n",
    "                 \"valor\"            : \"Amount\"}\n",
    "                df_fOrcamento = df_fOrcamento.rename( columns =  columns )\n",
    "    \n",
    "                tables_dict[file] = df_fOrcamento\n",
    "                print( f'{file} has been cleaned. It has {df_fOrcamento.shape[0]} rows ' )\n",
    "\n",
    "            elif file == 'fPrevisao.csv':\n",
    "                            # read data\n",
    "                query = 'SELECT * FROM [dbo].[fPrevisao.csv]'\n",
    "                df_fPrevisao = pd.read_sql( query , self.engine )\n",
    "    \n",
    "                # drop na\n",
    "                df_fPrevisao = df_fPrevisao.dropna(axis = 0)\n",
    "    \n",
    "                # change dtypes\n",
    "                df_fPrevisao['competencia_data'] = pd.to_datetime( df_fPrevisao['competencia_data'] ) \n",
    "                \n",
    "                # formatting integers numbers as .00\n",
    "                df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "                \n",
    "                # replace the last . for #\n",
    "                df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "                \n",
    "                # replace the last . for nothing\n",
    "                df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('.', '') )\n",
    "                \n",
    "                # replace # for .\n",
    "                df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "                \n",
    "                # convert value\n",
    "                df_fPrevisao['valor'] = df_fPrevisao['valor'].astype( 'float64' )\n",
    "                \n",
    "                # rename columns\n",
    "                columns = {\n",
    "                    \"competencia_data\": \"AccrualDate\",\n",
    "                     \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "                     \"valor\"           : \"Amount\"}\n",
    "                \n",
    "                df_fPrevisao = df_fPrevisao.rename( columns = columns )\n",
    "    \n",
    "                tables_dict[file] = df_fPrevisao\n",
    "                print( f'{file} has been cleaned. It has {df_fPrevisao.shape[0]} rows ' )\n",
    "\n",
    "            elif file.startswith( 'fLan' ):\n",
    "                \n",
    "                # read data\n",
    "                query = f'SELECT * FROM [dbo].[{file}]'\n",
    "                df_fLancamento = pd.read_sql( query , self.engine )\n",
    "                \n",
    "                # drop na\n",
    "                df_fLancamento = df_fLancamento.dropna(axis = 0)\n",
    "    \n",
    "                # change dtypes\n",
    "                df_fLancamento['competencia_data'] = pd.to_datetime( df_fLancamento['competencia_data'] )\n",
    "    \n",
    "                # formatting integers numbers as .00\n",
    "                df_fLancamento['valor'] = df_fLancamento['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "                \n",
    "                # replace the last . for #\n",
    "                df_fLancamento['valor'] = df_fLancamento['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "                \n",
    "                # replace the last . for nothing\n",
    "                df_fLancamento['valor'] = df_fLancamento['valor'].apply( lambda x: x.replace('.', '') )\n",
    "                \n",
    "                # replace # for .\n",
    "                df_fLancamento['valor'] = df_fLancamento['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "                \n",
    "                # convert value\n",
    "                df_fLancamento['valor'] = df_fLancamento['valor'].astype( 'float64' )\n",
    "                \n",
    "                # rename columns\n",
    "                columns = {\n",
    "                    \"competencia_data\":\"AccrualDate\",\n",
    "                    \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "                    \"valor\"           : \"Amount\"\n",
    "                }\n",
    "    \n",
    "                df_fLancamento = df_fLancamento.rename( columns = columns )\n",
    "                \n",
    "                df_Lan_final = pd.concat( [df_Lan_final , df_fLancamento] , ignore_index=True )\n",
    "    \n",
    "                print( f'Processing : {file}' )\n",
    "        print( f'df_Lan_final has been cleaned. It has {df_Lan_final.shape[0]} rows.' )\n",
    "    \n",
    "        tables_dict['dfLancamentos'] = df_Lan_final\n",
    "\n",
    "        return tables_dict\n",
    "\n",
    "    def load( self , tables_dict ):\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'STPE 3:LOAD' )\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'Creating Destination Database:' )\n",
    "\n",
    "        conn_temp = pyodbc.connect(f'Driver={{SQL Server}};Server={self.server};Trusted_Connection=yes;')\n",
    "        cursor_temp = conn_temp.cursor()\n",
    " \n",
    "        # check if a database already exists\n",
    "        check_db = f'''\n",
    "            IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{self.destination_database_name}' )\n",
    "                BEGIN\n",
    "                CREATE DATABASE {self.destination_database_name}\n",
    "                END\n",
    "        '''\n",
    "        # execute query\n",
    "        cursor_temp.execute( check_db )\n",
    "        cursor_temp.close()\n",
    "        conn_temp.close()\n",
    "        \n",
    "\n",
    "        print( f'{destination_database} database has been created.' )\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print( 'Data Loading:' )\n",
    "\n",
    "        # loading data\n",
    "        for table_name, df in tables_dict.items():\n",
    "    \n",
    "            df.to_sql( name = table_name , con = self.engine_db_destination , if_exists= 'replace', index = False)\n",
    "            print( f'{table_name} loaded into {self.destination_database_name}.' )\n",
    "            \n",
    "        print(\"=\"*100)\n",
    "        print( 'ETL STATUS: COMPLETED' )\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        # close engine connection\n",
    "        self.engine_db_destination.dispose()\n",
    "            \n",
    "        return None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0feadf90-de92-4426-8e18-545ba07bcad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STEP 1 :EXTRACT\n",
      "====================================================================================================\n",
      "Connecting Database:\n",
      "Successfull Connection\n",
      "====================================================================================================\n",
      "Checking Existing Database:\n",
      "Database checked\n",
      "====================================================================================================\n",
      "Loading Data:\n",
      "dEstruturaDRE.csv has been loaded into database\n",
      "dPlanoConta.csv has been loaded into database\n",
      "fLancamento1_ano1.csv has been loaded into database\n",
      "fLancamento1_ano2.csv has been loaded into database\n",
      "fLancamento1_ano3.csv has been loaded into database\n",
      "fLancamento2_ano1.csv has been loaded into database\n",
      "fLancamento2_ano2.csv has been loaded into database\n",
      "fLancamento2_ano3.csv has been loaded into database\n",
      "fLancamento3_ano1.csv has been loaded into database\n",
      "fLancamento3_ano2.csv has been loaded into database\n",
      "fLancamento3_ano3.csv has been loaded into database\n",
      "fOrcamento.csv has been loaded into database\n",
      "fPrevisao.csv has been loaded into database\n",
      "====================================================================================================\n",
      "STEP 2 :CLEANING DATA\n",
      "dEstruturaDRE.csv has been cleaned. It has 39 rows \n",
      "dPlanoConta.csv has been cleaned. It has 129 rows \n",
      "Processing : fLancamento1_ano1.csv\n",
      "Processing : fLancamento1_ano2.csv\n",
      "Processing : fLancamento1_ano3.csv\n",
      "Processing : fLancamento2_ano1.csv\n",
      "Processing : fLancamento2_ano2.csv\n",
      "Processing : fLancamento2_ano3.csv\n",
      "Processing : fLancamento3_ano1.csv\n",
      "Processing : fLancamento3_ano2.csv\n",
      "Processing : fLancamento3_ano3.csv\n",
      "fOrcamento.csv has been cleaned. It has 4644 rows \n",
      "fPrevisao.csv has been cleaned. It has 4644 rows \n",
      "df_Lan_final has been cleaned. It has 3741 rows.\n",
      "====================================================================================================\n",
      "STPE 3:LOAD\n",
      "====================================================================================================\n",
      "Creating Destination Database:\n",
      "DRE_Cleaned database has been created.\n",
      "====================================================================================================\n",
      "Data Loading:\n",
      "dEstruturaDRE.csv loaded into DRE_Cleaned.\n",
      "dPlanoConta.csv loaded into DRE_Cleaned.\n",
      "fOrcamento.csv loaded into DRE_Cleaned.\n",
      "fPrevisao.csv loaded into DRE_Cleaned.\n",
      "dfLancamentos loaded into DRE_Cleaned.\n",
      "====================================================================================================\n",
      "ETL STATUS: COMPLETED\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "server               = 'DESKTOP-U9M4TSR'\n",
    "file_dir             = 'D:/repos/ETL/data'\n",
    "staging_database     = 'DRE'\n",
    "destination_database = 'DRE_Cleaned'\n",
    "\n",
    "Test = ETL( server , file_dir , staging_database , destination_database )\n",
    "Test.extract()\n",
    "cleaned_tables = Test.transform()\n",
    "Test.load( cleaned_tables )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb0fe1-8414-4ade-8b40-a46a6a3739e4",
   "metadata": {},
   "source": [
    "## 1.0 Connecting to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "192376de-7ab1-48ea-a849-3e1ac6176e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull Connection\n"
     ]
    }
   ],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=DESKTOP-U9M4TSR;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "if conn:\n",
    "    print( \"Successfull Connection\" )\n",
    "else:\n",
    "    print( \"Connection Failded\" )\n",
    "\n",
    "# create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # closing cursor and connection\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8e6c1-7a7b-4b9a-b4cb-818fbca158ca",
   "metadata": {},
   "source": [
    "### 1.3 Check if a database exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86661906-fc72-40b8-9958-121f158710e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1a65a199530>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a database already exists\n",
    "database_name = 'DRE'\n",
    "check_db = f'''\n",
    "    IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{database_name}' )\n",
    "        BEGIN\n",
    "        CREATE DATABASE {database_name}\n",
    "        END\n",
    "'''\n",
    "# execute query\n",
    "cursor.execute( check_db )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd696e-7cd0-49bf-83a0-243e5058054f",
   "metadata": {},
   "source": [
    "### 1.4 Loading Tables into SQL Server Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e21ea6da-7d99-4c97-b973-28ee138b6f66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Attempt to use a closed cursor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mfile_name\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been loaded into database\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# closing cursor and connection\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mProgrammingError\u001b[0m: Attempt to use a closed cursor."
     ]
    }
   ],
   "source": [
    "SERVER = 'DESKTOP-U9M4TSR'\n",
    "# create sql alchemy connection\n",
    "connection_string = f'mssql+pyodbc://{SERVER}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "# create engine\n",
    "engine = create_engine( connection_string )\n",
    "\n",
    "# for each file in folder load csv files into database\n",
    "path = os.listdir()\n",
    "for file in path:\n",
    "    \n",
    "    file_name = file\n",
    "\n",
    "    if file.endswith( '.csv' ):\n",
    "        df = pd.read_csv( file_name, encoding = 'UTF-8' )\n",
    "        df.to_sql( name = file_name , con = engine , if_exists= 'replace', index = False)\n",
    "        print( f'{ file_name } has been loaded into database' )\n",
    "\n",
    "# closing cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d93d7-5e15-4c9d-94c6-4b5bb346b727",
   "metadata": {},
   "source": [
    "## 2 Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb0cbd-4dba-48d5-8586-b5359dbd361d",
   "metadata": {},
   "source": [
    "### dEstruturaDRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663df37b-a7bd-4212-9007-be158a9ffe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check na\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                955\n",
       "index             955\n",
       "contaGerencial    955\n",
       "subtotal          955\n",
       "empresa           955\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                float64\n",
       "index             float64\n",
       "contaGerencial     object\n",
       "subtotal          float64\n",
       "empresa            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes after changing dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                object\n",
       "index              int64\n",
       "contaGerencial    object\n",
       "subtotal           int64\n",
       "empresa           object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "query = 'SELECT * FROM [dbo].[dEstruturaDRE.csv]'\n",
    "df_dEstruturaDre = pd.read_sql( query , engine )\n",
    "\n",
    "# check na\n",
    "print( 'Check na' )\n",
    "display( df_dEstruturaDre.isna().sum() )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# drop na\n",
    "df_dEstruturaDre = df_dEstruturaDre.dropna(axis = 0)\n",
    "\n",
    "# check type\n",
    "print( 'Check dtypes' )\n",
    "display( df_dEstruturaDre.dtypes )\n",
    "\n",
    "# change dtypes\n",
    "df_dEstruturaDre['id']                = df_dEstruturaDre['id'].astype( 'str' )\n",
    "df_dEstruturaDre['index']             = df_dEstruturaDre['index'].astype( 'int64' )\n",
    "df_dEstruturaDre['contaGerencial']    = df_dEstruturaDre['contaGerencial'].astype( 'str' )\n",
    "df_dEstruturaDre['subtotal']          = df_dEstruturaDre['subtotal'].astype( 'int64' )\n",
    "df_dEstruturaDre['empresa']           = df_dEstruturaDre['empresa'].astype( 'str' )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check data type after transformations\n",
    "print( 'Check dtypes after changing dtypes' )\n",
    "display( df_dEstruturaDre.dtypes )\n",
    "\n",
    "# rename columns \n",
    "df_dEstruturaDre = df_dEstruturaDre.rename(columns = \n",
    "                        {'contaGerencial' : 'ManagementAccount', \n",
    "                          'empresa' : 'Branch', \n",
    "                          'subtotal' : 'Subtotal', \n",
    "                          'index' : 'Index'}  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a01f5e-52c0-4f68-83a4-516010afed41",
   "metadata": {},
   "source": [
    "### dPlanoConta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece9159b-061a-4b06-a473-b8d8a7ae2d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check na\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "index             0\n",
       "descricaoN1       0\n",
       "descricaoN2       0\n",
       "detalharN2        0\n",
       "mascaraDRE_id     0\n",
       "tipoLancamento    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                 object\n",
       "index               int64\n",
       "descricaoN1        object\n",
       "descricaoN2        object\n",
       "detalharN2          int64\n",
       "mascaraDRE_id     float64\n",
       "tipoLancamento      int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes after changing dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                object\n",
       "index              int64\n",
       "descricaoN1       object\n",
       "descricaoN2       object\n",
       "detalharN2         int64\n",
       "mascaraDRE_id     object\n",
       "tipoLancamento     int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "query = 'SELECT * FROM [dbo].[dPlanoConta.csv]'\n",
    "df_dPlanoConta = pd.read_sql( query , engine )\n",
    "\n",
    "# check na\n",
    "print( 'Check na' )\n",
    "display( df_dPlanoConta.isna().sum() )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# drop na\n",
    "df_dPlanoConta = df_dPlanoConta.dropna(axis = 0)\n",
    "\n",
    "# check type\n",
    "print( 'Check dtypes' )\n",
    "display( df_dPlanoConta.dtypes )\n",
    "\n",
    "# change dtypes\n",
    "df_dPlanoConta['mascaraDRE_id'] = df_dPlanoConta['mascaraDRE_id'].astype( 'str' )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check data type after transformations\n",
    "print( 'Check dtypes after changing dtypes' )\n",
    "display( df_dPlanoConta.dtypes )\n",
    "\n",
    "# rename columns\n",
    "columns = {\"descricaoN1\"   : \"DescriptionLevel1\", \n",
    " \"descricaoN2\"   : \"DescriptionLevel2\", \n",
    " \"detalharN2\"    : \"DetailLevel2?\",\n",
    " \"mascaraDRE_id\" : \"IncomeStatementTemplate_id\",\n",
    "\"tipoLancamento\" : \"EntryType\",\n",
    "\"index\"          : \"Index\"}\n",
    "\n",
    "df_dPlanoConta = df_dPlanoConta.rename( columns = columns )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf7cf7-1ce4-479b-92e2-9e8631808a72",
   "metadata": {},
   "source": [
    "### fOrcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e396da1d-883e-4359-aa91-7728e2466db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check na\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    0\n",
       "planoContas_id      0\n",
       "valor               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    object\n",
       "planoContas_id      object\n",
       "valor               object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes after changing dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    datetime64[ns]\n",
       "planoContas_id              object\n",
       "valor                      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "query = 'SELECT * FROM [dbo].[fOrcamento.csv]'\n",
    "df_fOrcamento = pd.read_sql( query , engine )\n",
    "\n",
    "# check na\n",
    "print( 'Check na' )\n",
    "display( df_fOrcamento.isna().sum() )\n",
    "\n",
    "# drop na\n",
    "df_fOrcamento = df_fOrcamento.dropna(axis = 0)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check type\n",
    "print( 'Check dtypes' )\n",
    "display( df_fOrcamento.dtypes )\n",
    "\n",
    "# change dtypes\n",
    "df_fOrcamento['competencia_data'] = pd.to_datetime( df_fOrcamento['competencia_data'] ) \n",
    "\n",
    "# formatting integers numbers as .00\n",
    "df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "\n",
    "# replace the last . for #\n",
    "df_fOrcamento['valor'] = df_fOrcamento['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "\n",
    "# replace the last . for nothing\n",
    "df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('.', '') )\n",
    "\n",
    "# replace # for .\n",
    "df_fOrcamento['valor'] = df_fOrcamento['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "\n",
    "# convert value\n",
    "df_fOrcamento['valor'] = df_fOrcamento['valor'].astype( 'float64' )\n",
    "\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check data type after transformations\n",
    "print( 'Check dtypes after changing dtypes' )\n",
    "display( df_fOrcamento.dtypes )\n",
    "\n",
    "# rename columns\n",
    "columns = {\"competencia_data\" : \"AccrualDate\",\n",
    " \"planoContas_id\"   : \"ChartOfAccounts_id\",\n",
    " \"valor\"            : \"Amount\"}\n",
    "df_fOrcamento = df_fOrcamento.rename( columns =  columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6aede5-1bb7-4455-a0c8-e620276ef326",
   "metadata": {},
   "source": [
    "### fPrevisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e164bffa-1010-41a8-886c-ec84262ca038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check na\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    0\n",
       "planoContas_id      0\n",
       "valor               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    object\n",
       "planoContas_id      object\n",
       "valor               object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes after changing dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    datetime64[ns]\n",
       "planoContas_id              object\n",
       "valor                      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "query = 'SELECT * FROM [dbo].[fPrevisao.csv]'\n",
    "df_fPrevisao = pd.read_sql( query , engine )\n",
    "\n",
    "# check na\n",
    "print( 'Check na' )\n",
    "display( df_fPrevisao.isna().sum() )\n",
    "\n",
    "# drop na\n",
    "df_fPrevisao = df_fPrevisao.dropna(axis = 0)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check type\n",
    "print( 'Check dtypes' )\n",
    "display( df_fPrevisao.dtypes )\n",
    "\n",
    "# change dtypes\n",
    "df_fPrevisao['competencia_data'] = pd.to_datetime( df_fPrevisao['competencia_data'] ) \n",
    "\n",
    "# formatting integers numbers as .00\n",
    "df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "\n",
    "# replace the last . for #\n",
    "df_fPrevisao['valor'] = df_fPrevisao['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "\n",
    "# replace the last . for nothing\n",
    "df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('.', '') )\n",
    "\n",
    "# replace # for .\n",
    "df_fPrevisao['valor'] = df_fPrevisao['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "\n",
    "# convert value\n",
    "df_fPrevisao['valor'] = df_fPrevisao['valor'].astype( 'float64' )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check data type after transformations\n",
    "print( 'Check dtypes after changing dtypes' )\n",
    "display( df_fPrevisao.dtypes )\n",
    "\n",
    "# rename columns\n",
    "columns = {\n",
    "    \"competencia_data\": \"AccrualDate\",\n",
    "     \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "     \"valor\"           : \"Amount\"}\n",
    "\n",
    "df_fPrevisao = df_fPrevisao.rename( columns = columns )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7771b-c5af-4620-8847-c0c8c48c3a45",
   "metadata": {},
   "source": [
    "### fLancamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5341e006-b685-4e28-b137-2febbf202d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check na\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    0\n",
       "planoContas_id      0\n",
       "valor               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    object\n",
       "planoContas_id      object\n",
       "valor               object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Check dtypes after changing dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "competencia_data    datetime64[ns]\n",
       "planoContas_id              object\n",
       "valor                      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "query = 'SELECT * FROM [dbo].[fLancamento1_ano1.csv]'\n",
    "df_fLancamento1_ano1 = pd.read_sql( query , engine )\n",
    "\n",
    "# check na\n",
    "print( 'Check na' )\n",
    "display( df_fLancamento1_ano1.isna().sum() )\n",
    "\n",
    "# drop na\n",
    "df_fLancamento1_ano1 = df_fLancamento1_ano1.dropna(axis = 0)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check type\n",
    "print( 'Check dtypes' )\n",
    "display( df_fLancamento1_ano1.dtypes )\n",
    "\n",
    "# change dtypes\n",
    "df_fLancamento1_ano1['competencia_data'] = pd.to_datetime( df_fLancamento1_ano1['competencia_data'] )\n",
    "\n",
    "# formatting integers numbers as .00\n",
    "df_fLancamento1_ano1['valor'] = df_fLancamento1_ano1['valor'].apply(lambda x: f\"{x}.00\" if '.' not in x else x)\n",
    "\n",
    "# replace the last . for #\n",
    "df_fLancamento1_ano1['valor'] = df_fLancamento1_ano1['valor'].apply(lambda x: '#'.join( x.rpartition('.') [::2] ))\n",
    "\n",
    "# replace the last . for nothing\n",
    "df_fLancamento1_ano1['valor'] = df_fLancamento1_ano1['valor'].apply( lambda x: x.replace('.', '') )\n",
    "\n",
    "# replace # for .\n",
    "df_fLancamento1_ano1['valor'] = df_fLancamento1_ano1['valor'].apply( lambda x: x.replace('#', '.') )\n",
    "\n",
    "# convert value\n",
    "df_fLancamento1_ano1['valor'] = df_fLancamento1_ano1['valor'].astype( 'float64' )\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check data type after transformations\n",
    "print( 'Check dtypes after changing dtypes' )\n",
    "display( df_fLancamento1_ano1.dtypes )\n",
    "\n",
    "# rename columns\n",
    "columns = {\n",
    "    \"competencia_data\":\"AccrualDate\",\n",
    "    \"planoContas_id\"  : \"ChartOfAccounts_id\",\n",
    "    \"valor\"           : \"Amount\"\n",
    "}\n",
    "\n",
    "df_fLancamento1_ano1 = df_fLancamento1_ano1.rename( columns = columns )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8a553-45e8-4061-bf9f-b661a11f75f3",
   "metadata": {},
   "source": [
    "## 3 Load "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ebf53-bd87-49c4-8757-cff406002700",
   "metadata": {},
   "source": [
    "### 3.1 Connecting to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8de18e05-e9df-41ab-a1e1-0fd3cefd6168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull Connection\n"
     ]
    }
   ],
   "source": [
    "server = 'DESKTOP-U9M4TSR'\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      f'Server={server};'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "if conn:\n",
    "    print( \"Successfull Connection\" )\n",
    "else:\n",
    "    print( \"Connection Failded\" )\n",
    "\n",
    "# create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # closing cursor and connection\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b81e7-75ef-4fa9-96e8-6c17c07b56fb",
   "metadata": {},
   "source": [
    "### 3.2 Cleaning and transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f7e4a3-1b9c-451b-95ea-afe4f6be4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dEstruturaDRE.csv has been cleaned. It has 39 rows \n",
      "dPlanoConta.csv has been cleaned. It has 129 rows \n",
      "Processing : fLancamento1_ano1.csv\n",
      "Processing : fLancamento1_ano2.csv\n",
      "Processing : fLancamento1_ano3.csv\n",
      "Processing : fLancamento2_ano1.csv\n",
      "Processing : fLancamento2_ano2.csv\n",
      "Processing : fLancamento2_ano3.csv\n",
      "Processing : fLancamento3_ano1.csv\n",
      "Processing : fLancamento3_ano2.csv\n",
      "Processing : fLancamento3_ano3.csv\n",
      "fOrcamento.csv has been cleaned. It has 4644 rows \n",
      "fPrevisao.csv has been cleaned. It has 4644 rows \n",
      "df_Lan_final has been cleaned. It has 3741 rows.\n"
     ]
    }
   ],
   "source": [
    "server = 'DESKTOP-U9M4TSR' # server containing the database where raw data is stored\n",
    "database_name = 'DRE'      # database where raw data is stored.\n",
    "\n",
    "\n",
    "tables = transform( server , database_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fe852-8d9b-4e8d-89d7-3c90f2ebdb33",
   "metadata": {},
   "source": [
    "### 3.3 Creating New DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac6e961-a70a-4021-a630-cac5085a4c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x27e182a7e30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a database already exists\n",
    "db_destiantion = 'DRE_Cleaned' # database where cleaned data will be stored.\n",
    "check_db = f'''\n",
    "    IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{database_name}' )\n",
    "        BEGIN\n",
    "        CREATE DATABASE {database_name}\n",
    "        END\n",
    "'''\n",
    "# execute query\n",
    "cursor.execute( check_db )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f110d3-242a-482d-87a3-071b786fd729",
   "metadata": {},
   "source": [
    "### 3.4 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e9aeca-b88f-416b-a27d-423f7a54a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dEstruturaDRE.csv loaded into DRE_Cleaned_Data.\n",
      "dPlanoConta.csv loaded into DRE_Cleaned_Data.\n",
      "fOrcamento.csv loaded into DRE_Cleaned_Data.\n",
      "fPrevisao.csv loaded into DRE_Cleaned_Data.\n",
      "dfLancamentos loaded into DRE_Cleaned_Data.\n"
     ]
    }
   ],
   "source": [
    "conn_string_db_destination = f'mssql+pyodbc://{SERVER}/{ db_destiantion }?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "# create engine\n",
    "engine_destination = create_engine( conn_string_db_destination )\n",
    "for table_name, df in tables.items():\n",
    "\n",
    "    df.to_sql( table_name , engine_destination , if_exists= 'replace', index = False)\n",
    "    print( f'{table_name} loaded into { db_destiantion}.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ac4648f-fc24-4c9b-82de-99ce581ee196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load( server, origin_database , destination_database ):\n",
    "\n",
    "    # db connections\n",
    "    conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      f'Server={server};'\n",
    "                      'Trusted_Connection=yes;')\n",
    "    conn_string_db_destination = f'mssql+pyodbc://{SERVER}/{ db_destiantion }?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    # create engine\n",
    "    engine_destination = create_engine( conn_string_db_destination )\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Connecting Database:' )\n",
    "\n",
    "    if conn:\n",
    "        print( \"Successfull Connection\" )\n",
    "    else:\n",
    "        print( \"Connection Failded\" )\n",
    "    \n",
    "    # create a cursor\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print( 'Data Cleaning:' )\n",
    "\n",
    "    # cleaning data\n",
    "    tables = transform( server , origin_database )\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Creating Destination Database:' )\n",
    " \n",
    "    # check if a database already exists\n",
    "    destination_database = 'DRE_Cleaned_Data' # database where cleaned data will be stored.\n",
    "    check_db = f'''\n",
    "        IF NOT EXISTS ( SELECT name FROM sys.databases WHERE name = '{destination_database}' )\n",
    "            BEGIN\n",
    "            CREATE DATABASE {destination_database}\n",
    "            END\n",
    "    '''\n",
    "    # execute query\n",
    "    cursor.execute( check_db )\n",
    "    cursor.close()\n",
    "\n",
    "    print( f'{destination_database} database has been created.' )\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print( 'Data Loading:' )\n",
    "\n",
    "    # loading data\n",
    "    for table_name, df in tables.items():\n",
    "\n",
    "        df.to_sql( table_name , engine_destination , if_exists= 'replace', index = False)\n",
    "        print( f'{table_name} loaded into {database_name}.' )\n",
    "    print(\"=\"*100)\n",
    "        \n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3bbaf55-57b4-4f2e-b552-7b501736cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Connecting Database:\n",
      "Successfull Connection\n",
      "====================================================================================================\n",
      "Data Cleaning:\n",
      "dEstruturaDRE.csv has been cleaned. It has 39 rows \n",
      "dPlanoConta.csv has been cleaned. It has 129 rows \n",
      "Processing : fLancamento1_ano1.csv\n",
      "Processing : fLancamento1_ano2.csv\n",
      "Processing : fLancamento1_ano3.csv\n",
      "Processing : fLancamento2_ano1.csv\n",
      "Processing : fLancamento2_ano2.csv\n",
      "Processing : fLancamento2_ano3.csv\n",
      "Processing : fLancamento3_ano1.csv\n",
      "Processing : fLancamento3_ano2.csv\n",
      "Processing : fLancamento3_ano3.csv\n",
      "fOrcamento.csv has been cleaned. It has 4644 rows \n",
      "fPrevisao.csv has been cleaned. It has 4644 rows \n",
      "df_Lan_final has been cleaned. It has 3741 rows.\n",
      "====================================================================================================\n",
      "Creating Destination Database:\n",
      "DRE_Cleaned_Data database has been created.\n",
      "====================================================================================================\n",
      "Data Loading:\n",
      "dEstruturaDRE.csv loaded into DRE.\n",
      "dPlanoConta.csv loaded into DRE.\n",
      "fOrcamento.csv loaded into DRE.\n",
      "fPrevisao.csv loaded into DRE.\n",
      "dfLancamentos loaded into DRE.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "server = 'DESKTOP-U9M4TSR'\n",
    "origin_database = 'DRE'\n",
    "destination_database = 'DRE_Cleaned_Data'\n",
    "load( server , origin_database , destination_database )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1614c88-8f2e-4a9c-9ee7-331e91703b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7dfcc-b5d5-4c02-a5e9-9aaa5461fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
